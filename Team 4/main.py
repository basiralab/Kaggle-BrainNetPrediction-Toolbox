"""
Target Problem:
---------------
* To train a model to predict the brain connectivity for the next time point given the brain connectivity at current time point.
Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* Preprocessing Method (if any) -> Dimensionality Reduction method (if any) -> Learner
Input to Proposed Solution:
---------------------------
* Directories of training and testing data in csv file format
* These two types of data should be stored in n x m pattern in csv file format.
  Typical Example:
  ----------------
  n x m samples in training csv file (Explain n and m) 
  k x s samples in testing csv file (Explain k and s

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "submission.csv" file. (Change the name file if needed)
Code Owner:
-----------
* Copyright © Team X. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Spring/Fall 2020. All rights reserved. 
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
from sklearn import metrics
from sklearn import preprocessing
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Ridge
from sklearn.ensemble import IsolationForest
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import RepeatedKFold
from sklearn.feature_selection import VarianceThreshold
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MaxAbsScaler
from sklearn.metrics import mean_squared_error as mse
from sklearn.metrics import mean_absolute_error as mae
from scipy.stats.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')
import random as r
r.seed(1)
import csv

def load_data(csvname):

    """
    The method reads train and test data from their dataset files.
    Then, it splits train data into features and labels.
    Parameters
    ----------
    train_file: directory of the file in which train data set is located
    test_file: directory of the file in which test data set is located
    """

    csv_file = pd.read_csv(csvname)
    data = csv_file.drop(['ID'],axis=1).to_numpy()
    return data



def preprocessing(x_tra, y_tra, x_tst):

    """
    * Explain the method
    * Explain which function does it
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    x_tst: features of test data
    """

    normalizer = MaxAbsScaler().fit(x_tra)
    X=normalizer.transform(x_tra)
    x_tst=normalizer.transform(x_tst)
    X_train=X
    X_test=x_tst
    sel = VarianceThreshold(threshold=(.0001 * (1 - .0001)))
    X_train=sel.fit_transform(X_train)
    #y_train=sel.fit_transform(y_train)
    X_test=sel.fit_transform(X_test)
    #y_test=sel.fit_transform(y_test)
    # identify outliers in the training dataset
    iso = IsolationForest(contamination=0.01)
    yhat = iso.fit_predict(X_train)
    # select all rows that are not outliers
    mask = yhat != -1
    X_train, y_train = X_train[mask, :], y_tra[mask]
    # summarize the shape of the updated training dataset
    print(X_train.shape, y_train.shape)
    return X_train,y_train,X_test


def train_ridge_model(x_tra, y_tra):

    """
    The method creates a learning model and trains it by using training data.
    Parameters
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    """

    cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1)
    clf = Ridge()
    ridge_regressor = None
    parameters= {'alpha': np.arange(0,20,1)} #possible alpha values
    ridge_regressor = GridSearchCV(clf, parameters, scoring='neg_mean_squared_error', cv= cv)
    ridge_regressor.fit(x_tra, y_tra)
    return ridge_regressor
def predict_ridge(x_tst, model):

    """
    The method predicts labels for testing data samples by using trained learning model.
    Parameters
    ----------
    x_tst: features of testing data
    model: trained learning model
    """
    prediction = model.predict(x_tst)
    return prediction


def train_linear_model(x_tra, y_tra):

    """
    The method creates a learning model and trains it by using training data.
    Parameters
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    """

    models = []
    for i in range(x_tra.shape[1]):
        regressor = LinearRegression() 
        regressor.fit(x_tra[:,i].reshape(x_tra.shape[0],1), y_tra[:,i].reshape(y_tra.shape[0],1)) 
        models.append(regressor)
        
    
    return models
np.random.seed(1)

def predict_linear(x_tst, model):

    """
    The method predicts labels for testing data samples by using trained learning model.
    Parameters
    ----------
    x_tst: features of testing data
    model: trained learning model
    """
    predict = np.array([])
    for i in range(len(model)):
        predicted_values=model[i].predict(x_tst[:,i].reshape(x_tst.shape[0],1))
        if(i==0):
            predict=predicted_values.T
        else:
            predict = np.vstack((predict,predicted_values.T))
        
    return predict.T


def write_output(filename,predictions):
    """
        Writes predictions as desired in the submission process
    Parameters
    ----------
    filename: file path for saving file
    predictions: predictions after testing
    """
    with open(filename, mode='w') as output_file:
        output_writer = csv.writer(output_file, delimiter=',')
        output_writer.writerow(["ID", "Predicted"])

        for i in range(len(predictions)):
            output_writer.writerow([i, predictions[i]])

def cv5(train_X,train_y):
    column_names=[]
    for i in range(1,596):
        column_names.append("f"+str(i))
    kf = KFold(n_splits=5, shuffle=True, random_state=1)

    Five_fold_predictions = []
    Mse_results = []
    Mae_results = []
    test_indexes = []

    final_prediction = np.zeros(train_X.shape[0]*595).reshape(train_X.shape[0],595)

    X = train_X
    y = train_y

    counter=0
    for train_index, test_index in kf.split(X):
        counter+=1
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]
        test_indexes.append(test_index)
        #print("Mse of Cross Validation "+str(counter)+":")
        x_train_red,y_train_red, x_test_red  =  preprocessing(X_train, y_train, X_test)
        ridge_model = train_ridge_model(x_train_red, y_train_red)
        
        linear_models = train_linear_model(X_train, y_train)
        # We combined these two models to increase the accuracy
        pred_ridge = predict_ridge(x_test_red, ridge_model)
        pred_linear = predict_linear(X_test, linear_models)
        prediction = (pred_ridge+pred_linear)/2
        
        for i in range(0, len(test_index)):
            final_prediction[test_index[i],:] = prediction[i]
        
        Five_fold_predictions.append(prediction)
        Mse_results.append(mse(prediction, y_test))
        Mae_results.append(mae(prediction, y_test))
        
        print("pearson:",pearsonr(prediction.flatten(),y_test.flatten()))
        #print("mae:",mae(prediction, y_test))
        #print("mse:",mse(prediction, y_test))
    print(sum(Mae_results)/5)
    print(np.std(Mae_results))
    print(sum(Mse_results)/5)
    print(np.std(Mse_results))
    
# ********** MAIN PROGRAM ********** #
X = load_data("train_t0.csv")
y = load_data("train_t1.csv")
X_test = load_data("test_t0.csv")

X_red,y_red,X_test_red = preprocessing(X,y,X_test)

ridge_model = train_ridge_model(X_red,y_red)
linear_models = train_linear_model(X,y)
ridge_pred = predict_ridge(X_test_red,ridge_model)
linear_pred = predict_linear(X_test,linear_models)
prediction = (linear_pred+ridge_pred)/2

write_output("result.csv",prediction.flatten())
cv5(X,y)
