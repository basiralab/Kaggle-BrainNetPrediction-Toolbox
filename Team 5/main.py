"""
Target Problem:
---------------
* To train a model to predict the brain connectivity for the next time point given the brain connectivity at current time point.
Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* Preprocessing Method (if any) -> Dimensionality Reduction method (if any) -> Learner
Input to Proposed Solution:
---------------------------
* Directories of training and testing data in csv file format
* These two types of data should be stored in n x m pattern in csv file format.
  Typical Example:
  ----------------
  n x m samples in training csv file (Explain n and m) 
  k x s samples in testing csv file (Explain k and s

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "submission.csv" file. (Change the name file if needed)
Code Owner:
-----------
* Copyright © Team X. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Spring/Fall 2020. All rights reserved. 
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pandas_profiling
#import lightgbm as lgb
from sklearn.feature_selection import RFE
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold
from sklearn.inspection import permutation_importance
from sklearn.metrics import mean_squared_error as mse
from sklearn.feature_selection import SelectKBest, RFE, chi2, f_regression
from sklearn.metrics import mean_absolute_error as mae
from scipy.stats.stats import pearsonr
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
#import xgboost as xgb
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.svm import SVR
from sklearn.metrics import make_scorer
import os
import random as r
import csv
r.seed(1)
def load_data(filename):

    """
    The method reads train and test data from their dataset files.
    Then, it splits train data into features and labels.
    Parameters
    ----------
    train_file: directory of the file in which train data set is located
    test_file: directory of the file in which test data set is located
    """

    df = pd.read_csv(filename)
    return df
def preprocessing(x_tra, y_tra, x_tst):

    """
    * Explain the method
    * Explain which function does it
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    x_tst: features of test data
    """
    
    train_y = y_tra.copy().drop(columns = 'ID')
    # Clear outstanding outliers 
    train_y  =  train_y.apply(lambda x: [y if y < 1 else x[x<1].mean() for y in x])
    # Clear outliers which are greater than mean of that feature *3 
    for key in y_tra.keys().to_list()[1:]:
        col_mean = x_tra[key].mean()
        x_tra.loc[x_tra[key] > col_mean *3, key] = col_mean
        col_mean = x_tst[key].mean()
        x_tst.loc[x_tst[key] > col_mean *3, key] = col_mean
        col_mean = train_y[key].mean()
        train_y.loc[train_y[key] > col_mean *3, key] = col_mean
        
    x_tra = x_tra.drop(columns = 'ID')
    x_tst = x_tst.drop(columns = 'ID')
    return x_tra, train_y, x_tst

def train_model(x_tra, y_tra):

    """
    The method creates a learning model and trains it by using training data.
    Parameters
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    """

    #Define Model and fit
    rand_forest = MultiOutputRegressor(RandomForestRegressor(n_estimators=600, max_depth = 160,min_samples_split = 26, min_samples_leaf = 7, max_features = 12, n_jobs = os.cpu_count()-1))
    rand_forest.fit(x_tra, y_tra)
    return rand_forest

def predict(x_tst, model):

    """
    The method predicts labels for testing data samples by using trained learning model.
    Parameters
    ----------
    x_tst: features of testing data
    model: trained learning model
    """
    #Define Model and fit
    preds = model.predict(x_tst)
    return preds

def write_output(filename,predictions):
    """
        Writes predictions as desired in the submission process
    Parameters
    ----------
    filename: file path for saving file
    predictions: predictions after testing
    """
    with open(filename, mode='w') as output_file:
        output_writer = csv.writer(output_file, delimiter=',')
        output_writer.writerow(["ID", "Predicted"])

        for i in range(len(predictions)):
            output_writer.writerow([i, predictions[i]])



def cv5(train_X,train_y):
    kf = KFold(n_splits=5, shuffle=True, random_state=1)

    Five_fold_predictions = []
    Mse_results = []
    Mae_results = []
    test_indexes = []


    X = train_X
    y = train_y

    counter=0
    for train_index, test_index in kf.split(X):
        counter+=1
        X_train, X_test = X.loc[train_index], X.loc[test_index]
        y_train, y_test = y.loc[train_index], y.values[:,1:][test_index]
        test_indexes.append(test_index)
        print("Mse of Cross Validation "+str(counter)+":")

        X_red,y_red,X_t_red = preprocessing(X_train,y_train,X_test)
        print(y_red.shape)
        model = train_model(X_red,y_red)
        prediction = predict(X_t_red,model)
        
        Five_fold_predictions.append(prediction)
        Mse_results.append(mse(prediction, y_test))
        Mae_results.append(mae(prediction, y_test))
        print("pearson:",pearsonr(prediction.flatten(),y_test.flatten()))
        #print("mae:",mae(prediction, y_test))
        #print("mse:",mse(prediction, y_test))
        print("mae ----------------------")
        
    print(sum(Mae_results)/5)
    print(np.std(Mae_results))
    print(sum(Mse_results)/5)
    print(np.std(Mse_results))





# ********** MAIN PROGRAM ********** #
np.random.seed(1)
X_train = load_data('train_t0.csv')
y_train = load_data('train_t1.csv')
X_test = load_data('test_t0.csv')

cv5(X_train,y_train)


X_red,y_red,X_t_red = preprocessing(X_train,y_train,X_test)
print(y_red.shape)
model = train_model(X_red,y_red)

train_prediction = predict(X_red,model)

X_test = X_test.drop(columns = 'ID')
test_prediction = predict(X_test,model)


write_output('predictions.csv',test_prediction.flatten())
print("...")
print("Predicted file for X_test is written to the predictions.csv file")

