"""
Target Problem:
---------------
* Predict the evolution of brain connectivity over time.

Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* Constant Feature Elimination -> Local Outlier Factor -> Partial Least Squares Regression -> Bagging Regression

Input to Proposed Solution:
---------------------------
* Directories of training data and labels(measurements at two different timepoints), and testing data in csv file format.
* These data should be stored in n x m pattern in csv file format.

  Typical Example:
  ----------------
  n x m samples in train_t0 csv file (n number of samples, m number of features)
  n x m samples in train_t1 csv file (n number of samples, m number of features)
  k x m samples in test_t0 csv file (k number of samples, m number of features)

* These data set files are ready by load_data() function.

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "submission.csv" file.

Code Owner:
-----------
* Copyright © Team 6. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Fall 2021. All rights reserved.
"""


import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import random as r
from sklearn.cross_decomposition import PLSRegression
from sklearn.metrics import mean_squared_error as mse
from sklearn.neighbors import LocalOutlierFactor
from sklearn.ensemble import BaggingRegressor
from sklearn.model_selection import KFold
import statistics

r.seed(1)


def load_data(train_file, test_file):

    """
    The method reads train and test data from their dataset files.
    Then, it splits train data into features and labels.
    Parameters
    ----------
    train_file: directory of the file in which train data set is located
    test_file: directory of the file in which test data set is located
    """

    x_tra = pd.read_csv(train_file[0], index_col="ID")
    y_tra = pd.read_csv(train_file[1], index_col="ID")
    x_tst = pd.read_csv(test_file, index_col="ID")
    return x_tra, y_tra, x_tst


def preprocessing(x_tra, y_tra, x_tst):

    """
    * The method at first eliminates constant features from both train and test data.
    * Then, the method runs local outlier factor on the training sets, then returns
      the samples that are not outliers.
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    x_tst: features of test data
    """
    
    x_tra = x_tra.drop(["f4", "f466", "f469", "f497", "f500", "f528"], axis = 1)
    x_tst = x_tst.drop(["f4", "f466", "f469", "f497", "f500", "f528"], axis = 1)

    lof = LocalOutlierFactor(n_neighbors=125)
    x_tra_index = lof.fit_predict(x_tra)
    y_out_index = lof.fit_predict(y_tra)

    sample_len = x_tra_index.shape

    list1 = []
    for i in range(0, sample_len[0]):
        if x_tra_index[i] == -1:
            list1.append(i)

    list2 = []
    for i in range(0, sample_len[0]):
        if y_out_index[i] == -1:
            list2.append(i)

    b = set(list2) - set(list1)
    b = list(b)
    b.sort()

    final_drop = b + list1

    x_tra = x_tra.drop(final_drop, axis=0)
    y_tra = y_tra.drop(final_drop, axis=0)

    return x_tra, y_tra, x_tst

def train_model(x_tra, y_tra):

    """
    The method creates a learning model and trains it by using training data.
    Parameters
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    """

    model = {}

    for col in y_tra:
        if col in ("f4", "f466", "f469", "f497", "f500", "f528"):
            model[col] = "zero"
            continue
        pls2 = PLSRegression(n_components=2)
        rf = BaggingRegressor(base_estimator=pls2, n_estimators=175, random_state=0, n_jobs=-1)
        rf.fit(x_tra.to_numpy(), y_tra[col].values)
        model[col] = rf
    return model

def predict(x_tst, model):

    """
    The method predicts labels for testing data samples by using trained learning model.
    Parameters
    ----------
    x_tst: features of testing data
    model: trained learning model
    """

    predictions = pd.DataFrame()
    for col in model:
        if col in ("f4", "f466", "f469", "f497", "f500", "f528"):
            predictions[col] = np.zeros(x_tst.shape[0])
            continue
        predictions[col] = model[col].predict(x_tst).reshape(1, -1)[0]
    return predictions

def cross_validation(x_tra, y_tra):

    """
    The method performs 5-fold cross-validation on training data and returns the error rates.
    Parameters
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    """

    cv_splits = KFold(n_splits=5, shuffle=True, random_state=1)

    error_rates = []
    for train_index, test_index in cv_splits.split(x_tra):
        x_tra_cv, x_tst_cv, y_tra_cv, y_tst_cv = x_tra.iloc[train_index], x_tra.iloc[test_index], y_tra.iloc[train_index], y_tra.iloc[test_index]
        x_tra_cv, y_tra_cv, x_tst_cv = preprocessing(x_tra_cv, y_tra_cv, x_tst_cv)

        model = train_model(x_tra_cv, y_tra_cv)
        y_preds = predict(x_tst_cv, model)

        y_tst_cv = y_tst_cv.to_numpy().flatten()
        y_preds = y_preds.to_numpy().flatten()

        error_rates.append(mse(y_tst_cv, y_preds))
        del model

    return error_rates, statistics.mean(error_rates)

def write_output(filename,predictions):
    
    """
    Writes the outputted predictions to a file.
    Parameters
    ----------
    filename: file path for saving file
    predictions: pandas.dataframe object containing predictions
    """

    meltedDF = predictions.flatten()
    kaglexd = pd.DataFrame(meltedDF)
    kaglexd_melted = kaglexd.melt()
    kaglexd_melted.drop('variable', inplace=True, axis=1)

    kaglexd_melted = kaglexd_melted.rename(columns={'value': 'predicted'})
    kaglexd_melted.index.name = 'ID'

    kaglexd_melted.to_csv(filename)

# ********** MAIN PROGRAM ********** #


train_file, test_file = ["train_t0.csv", "train_t1.csv"], "test_t0.csv"
x_tra, y_tra, x_tst = load_data(train_file, test_file)

error_rates, mean = cross_validation(x_tra, y_tra)
print(mean)

x_tra, y_tra, x_tst = preprocessing(x_tra, y_tra, x_tst)
model = train_model(x_tra, y_tra)
predictions = predict(x_tst, model)
