"""
Target Problem:
---------------
* To train a model to predict the brain connectivity for the next time point given the brain connectivity at current time point.
Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* K-NN
Input to Proposed Solution:
---------------------------
* Directories of training and testing data in csv file format
* These two types of data should be stored in n x m pattern in csv file format.
  Typical Example:
  ----------------
  n x m samples in training csv file (Explain n and m) 
  k x s samples in testing csv file (Explain k and s

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "results_team12.csv" file. (Change the name file if needed)
Code Owner:
-----------
* Copyright © Team 12. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Spring/Fall 2020. All rights reserved. 
"""

import pandas as pd
from sklearn.model_selection import KFold
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.neighbors import NearestNeighbors
from scipy.stats.stats import pearsonr
import random as r
r.seed(1)
np.random.seed(1)
import warnings
warnings.filterwarnings('ignore')


def load_data(csv):
    """
    The method reads train and test data from their dataset files.
    Then, it splits train data into features and labels.
    Parameters
    ----------
    train_file: directory of the file in which train data set is located
    test_file: directory of the file in which test data set is located
    """
    # reading the data from the csv files
    df = pd.read_csv(csv, sep=',')
    # ignoring the index column of the data (0,...,149 or 0,...,79)
    df = df.drop(columns=['ID'])
    df_np = df.to_numpy()
    return df_np


def train_model(train_t0, neighbourCount):
    """
    The method creates a learning model and trains it by using training data.
    Parameters
    ----------
    train_t0: x
    neighbourCount: number of neigbours in KNN
    """
    nbrs = []
    train_t0_single = np.transpose(train_t0)
    for i in range(train_t0_single.shape[0]):
        nbrs.append(NearestNeighbors(n_neighbors=neighbourCount, algorithm='ball_tree').fit(train_t0_single[i].reshape(-1,1)))
    return nbrs

def predict(train_t0, train_t1, test_t0, nbrs):

    """
    The method makes predictions for testing data samples by using trained learning model.
    Parameters
    ----------
    train_t0: x
    train_t1: y
    test_t0: x_test
    nbrs: Nearest Neigbors model for each feature
    """
    train_t0_single = np.transpose(train_t0)
    train_t1_single = np.transpose(train_t1)
    test_t0_single = np.transpose(test_t0)
    prediction = np.zeros_like(test_t0)
    for i in range(train_t0_single.shape[0]):
        distances, indices = nbrs[i].kneighbors(test_t0_single[i].reshape(-1,1))
        distances = np.ones_like(distances)* 0.7 - distances
        mul = np.multiply(distances, train_t1_single[i,indices])  
        pred = np.divide(np.mean(mul, axis =1), np.mean(distances, axis = 1))
        prediction[:,i] = pred.reshape(-1)
    nanLocations = np.isnan(prediction)
    prediction[nanLocations] = 0    
    return prediction

def cv5(data_t0, data_t1, neighbourCount):
    kf = KFold(n_splits=5 , shuffle = True, random_state=1)
    prediction_all = np.zeros_like(data_t1)
    mses= []
    maes = []
    pears = []
    for trainIndex, testIndex in kf.split(data_t0):
        train_t0, test_t0 = data_t0[trainIndex], data_t0[testIndex] #Split Data into train and test sets
        train_t1, test_t1 = data_t1[trainIndex], data_t1[testIndex]
        train_t0_single = np.transpose(train_t0) # Use features as rows and subjects as columns
        train_t1_single = np.transpose(train_t1)
        test_t0_single = np.transpose(test_t0) 
        prediction = np.zeros_like(test_t0)
        preds = []
        for i in range(train_t0_single.shape[0]): #Loop through each feature
            
            nbrs = NearestNeighbors(n_neighbors= neighbourCount, algorithm='ball_tree').fit(train_t0_single[i].reshape(-1,1))
            distances, indices = nbrs.kneighbors(test_t0_single[i].reshape(-1,1))# Calculate the distances and indices of K closest neighbours of test subjects and train subjects in t0 
            distances = np.ones_like(distances)* 0.7 - distances # Set distances to (0.7 - d). Neighbours with low distance get larger values and vice versa  
            mul = np.multiply(distances, train_t1_single[i,indices])  # Use the changed distances as weights and multiply the corresponding t1 of the neighbours 
            pred = np.divide(np.mean(mul,axis =1),np.mean(distances, axis = 1)) #Take the mean of the weighted t1's and divide by the mean of distances to normalize 
            prediction[:,i] = pred.reshape(-1) #This is the prediction for this feature acroos all test subjects
            preds.append(pred.reshape(-1))

        nanLocations = np.isnan(prediction)
        prediction[nanLocations] = 0   # Set nan locations to 0
        
        preds = np.asarray(preds)
        preds = np.transpose(preds)
        mses.append( mean_squared_error(preds, test_t1) )
        maes.append( mean_absolute_error(preds, test_t1) )
        pears.append(pearsonr(preds.flatten(), test_t1.flatten())[0] )
        prediction_all[testIndex] = prediction # Put all predictions for each CV fold into prediction_all
    mse_error = mean_squared_error(data_t1, prediction_all)
    mae_error = mean_absolute_error(data_t1, prediction_all)
    print("mses: ", mses)
    print("maes: ", maes)
    print("pears", pears)
    print("Average error of five fold cross validation MSE:", np.sum(mses) / 5)
    print("Average error of five fold cross validation MAE:", np.sum(maes) / 5)
    print("Average error of five fold cross validation pearson:", np.sum(pears) / 5)
    print(" std of five fold cross validation MSE:", np.std(mses))
    print(" std of five fold cross validation MAE:", np.std(maes))
    print(" std of five fold cross validation pearson:", np.std(pears))
    return mae_error, mse_error, prediction_all




def write_output(filename, predictions):
    test_df = pd.DataFrame(predictions)
    melted_df = test_df.to_numpy().flatten()
    melted_df = pd.DataFrame(data=melted_df, columns=['Predicted'])
    melted_df['ID'] = [i for i in range(len(melted_df))]
    melted_df = melted_df[['ID', 'Predicted']]
    melted_df.to_csv(filename+'.csv', index=False)

# ********** MAIN PROGRAM ********** #
train_t0 = load_data("train_t0.csv")
train_t1 = load_data("train_t1.csv")
test_t0 = load_data("test_t0.csv")

neighbourCount = 55
nbrs = train_model(train_t0, neighbourCount)
predictions = predict(train_t0, train_t1, test_t0, nbrs)
write_output("results_team12", predictions)

mae_error, mse_error, prediction  = cv5(train_t0, train_t1, neighbourCount)
