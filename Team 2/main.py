"""
Target Problem:
---------------
* To train a model to predict the brain connectivity for the next time point given the brain connectivity at current time point.
Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* Preprocessing Method (if any) -> Dimensionality Reduction method (if any) -> Learner
Input to Proposed Solution:
---------------------------
* Directories of training and testing data in csv file format
* These two types of data should be stored in n x m pattern in csv file format.
  Typical Example:
  ----------------
  n x m samples in training csv file (Explain n and m) 
  k x s samples in testing csv file (Explain k and s

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "submission.csv" file. (Change the name file if needed)
Code Owner:
-----------
* Copyright © Team X. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Spring/Fall 2020. All rights reserved. 
"""

import numpy as np
import pandas as pd
import random

from sklearn.multioutput import  MultiOutputRegressor
from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor
from sklearn.metrics import mean_squared_error as mse
from sklearn.model_selection import GridSearchCV
from sklearn.svm import LinearSVR, SVR
from sklearn.model_selection import KFold,GridSearchCV
import csv
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error as mae
from scipy.stats.stats import pearsonr



import warnings
warnings.filterwarnings('ignore')

from sklearn.linear_model import  LinearRegression,ElasticNet,SGDRegressor,BayesianRidge,HuberRegressor

import random as r
r.seed(1)
np.random.seed(1)
def load_data(csvname):

    """
    The method reads train and test data from their dataset files.
    Then, it splits train data into features and labels.
    Parameters
    ----------
    train_file: directory of the file in which train data set is located
    test_file: directory of the file in which test data set is located
    """
    df = pd.read_csv(csvname)
    data = np.array(df)[:,1:]
    return data

def write_output(filename,predictions):
    """
        Writes predictions as desired in the submission process
    Parameters
    ----------
    filename: file path for saving file
    predictions: predictions after testing
    """
    with open(filename, mode='w') as output_file:
        output_writer = csv.writer(output_file, delimiter=',')
        output_writer.writerow(["ID", "Predicted"])

        for i in range(len(predictions)):
            output_writer.writerow([i, predictions[i]])

def train_model(x_tra, y_tra):

    """
    The method creates a learning model and trains it by using training data.
    Parameters
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    """
    models = []
    for i in range(x_tra.shape[1]):
        model = HuberRegressor(epsilon=1.5,alpha=1,max_iter=100000)
        frst = x_tra[:,i].reshape(-1,1)
        sec = y_tra[:,i].reshape(-1,1)
        model.fit(frst, sec)
        models.append(model)
    print(len(models))
    return models



def predict(x_tst, models):

    """
    The method predicts labels for testing data samples by using trained learning model.
    Parameters
    ----------
    x_tst: features of testing data
    model: trained learning model
    """

    arr = []
    for i in range(x_tst.shape[1]):

        tes = x_tst[:,i].reshape(-1,1)
        pred2 = models[i].predict(tes)
        arr.append(pred2.T)

    
    npl = np.array(arr)
    print(npl.shape)
    npl = npl.T.reshape(-1,595)
    print(npl.shape)

    return npl
    
def cv5(Xt0, Xt1, cv=5):
    kf = KFold(n_splits=cv, shuffle=True,random_state=1)
    kf.get_n_splits(Xt0)
    scores = []
    mad = []
    r2r = []

     # splitting into k folds

    print("MSE / MAE / R SQUARED SCORES FOR {} \n".format(cv))
    for train_index, test_index in kf.split(Xt0):
        X_train, X_test = Xt0[train_index], Xt0[test_index]
        y_train, y_test = Xt1[train_index], Xt1[test_index]


        arr = []
        # splitting all 595 points and calculates results for each
        for i in range(Xt0.shape[1]):
            model = HuberRegressor(epsilon=1.5,alpha=1,max_iter=100000)
            frst = X_train[:,i].reshape(-1,1)
            sec = y_train[:,i].reshape(-1,1)
            model.fit(frst, sec)
            tester = X_test[:,i].reshape(-1,1)
            preds = model.predict(tester)
            arr.append(preds.T)

        # reshaping and stacking them together.
        res = np.array(arr)
        res = res.T.reshape(-1,595)
        #score calculating
        score = mse(y_test, res)
        mae_e = mae(y_test, res)
        scores.append(score)
        r2sc = r2_score(y_test, res)
        #print(pearsonr(y_test.flatten(),res.flatten()))

        mad.append(mae_e)
        r2r.append(r2sc)
        
        # score printing
        #print("MSE score for fold {}: {:.5f}".format(len(scores), score))
        #print("MAE score for fold {}: {:.5f}".format(len(mad), mae_e))
        #print("R2 score for fold {}: {:.5f}\n".format(len(r2r), r2sc))
        
    print("Mean MSE score across folds: {:.5f}".format(sum(scores) / len(scores)))
    print("Mean MAE score across folds: {:.5f}".format(sum(mad) / len(mad)))
    print("Mean R2 score across folds: {:.5f}".format(sum(r2r) / len(r2r)))


# ********** MAIN PROGRAM ********** #
from datetime import datetime



X_train = load_data('train_t0.csv')
y_train = load_data('train_t1.csv')
X_test = load_data('test_t0.csv')


print(X_train.shape)
print(y_train.shape)

cv5(X_train,y_train)
models = train_model(X_train,y_train)

train_pred = predict(X_train, models)
test_pred = predict(X_test, models)

print("a:",test_pred.shape)
print(mse(train_pred,y_train))

write_output("huber_linear_modela.csv", test_pred.flatten())
print("CSV file is created.")
