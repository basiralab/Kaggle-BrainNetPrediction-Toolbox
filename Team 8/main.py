"""
Target Problem:
---------------
* Predict the evolution of brain connectivity over time.

Proposed Solution (Machine Learning Pipeline):
----------------------------------------------
* Constant Feature Elimination -> SelectKBest Algorithm -> VotingRegressor(AdaBoostRegressor, GradientBoostingRegressor, KNeighborsRegressor)

Input to Proposed Solution:
---------------------------
* Directories of training data and labels(measurements at two different timepoints), and testing data in csv file format.
* These data should be stored in n x m pattern in csv file format.

  Typical Example:
  ----------------
  n x m samples in train_t0 csv file (n number of samples, m number of features)
  n x m samples in train_t1 csv file (n number of samples, m number of features)
  k x m samples in test_t0 csv file (k number of samples, m number of features)

* These data set files are ready by load_data() function.

Output of Proposed Solution:
----------------------------
* Predictions generated by learning model for testing set
* They are stored in "submission.csv" file.

Code Owner:
-----------
* Copyright © Team 8. All rights reserved.
* Copyright © Istanbul Technical University, Learning From Data Fall 2021. All rights reserved.
"""

import pandas as pd
import numpy as np
from sklearn.feature_selection import SelectKBest, mutual_info_regression
from sklearn.ensemble import AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor
from sklearn.base import BaseEstimator
from sklearn.model_selection import KFold, GridSearchCV
from sklearn.metrics import mean_squared_error as mse
from sklearn.metrics import mean_absolute_error as mae
from scipy.stats import pearsonr as pr
from sklearn.neighbors import KNeighborsRegressor
from sklearn.pipeline import Pipeline
from itertools import combinations
import statistics
import random as r

np.random.seed(1)
r.seed(1)


class CustomRegressor(BaseEstimator):
    """
    Custom regressor class that is inherited from BaseEstimator class from sci-kit learn.
    This custom regressor is a custom version of the VotingRegressor, modified so that it
    can change the base models that are used at each iteration of cross-validation search.
    """

    def __init__(self, regressors = ("adb", AdaBoostRegressor())):
        #Base models are passed in as (name, instance) tuples as usual
        self.regressors = regressors

    def fit(self, X, y):
        #Creates and fits a VotingRegressor instance.
        self.regressor_ = VotingRegressor(estimators = self.regressors, n_jobs=-1)
        self.regressor_.fit(X, y)
        return self
    
    def predict(self, X, y=None):
        #Returns predictions
        return self.regressor_.predict(X)
    
    def transform(self, X, y=None):
        #Might be required for GridSearchCV
        return self.regressor_.transform(X)

    def score(self, X, y=None):
        #Returns score
        return self.regressor_.score(X, y)
        

def load_data(files):
    
    """
    The method reads train and test data from their dataset files.
    Then, it splits train data into features and labels.
    Parameters
    ----------
    train_file: directory of the file in which train data set is located
    test_file: directory of the file in which test data set is located
    """

    train_data = pd.read_csv(files[0], index_col="ID")
    train_label = pd.read_csv(files[1], index_col="ID")
    test_data = pd.read_csv(files[2], index_col="ID")
    return train_data, train_label, test_data

def preprocessing(x_tra, y_tra, x_tst):
    
    """
    * The method at first eliminates constant features from both train and test data.
    * Then, the method runs selectKBest algorithm on the dataset, returning top 350 features.
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    x_tst: features of test data
    """

    return x_tra.drop(["f4","f466","f469","f497","f500","f528"], axis=1), x_tst.drop(["f4","f466","f469","f497","f500","f528"], axis=1)

def grid_search(train_data, train_label, params, col, k=350):

    """
    This function calls estimators() function to get all
    the possible regressor models that it will use. Then 
    it initializes a pipeline object, which includes
    a selector object and our unfitted CustomRegressor object.
    This pipeline will prevent data leak in our selector as
    it will enable it to be fit with seperate training and
    testing data at each fold of GridSearchCV. Then we use
    this pipeline in our GridSearchCV object to get the best
    fitted estimator possible that uses a combination of our 
    base estimators. Then we return the fitted estimator.
    -----------------------------------------------------
    train_data: Training dataset
    train_label: Training label
    """

    estimators = get_estimators(params, col)
    pipeline = Pipeline([
        ("selector", SelectKBest(mutual_info_regression, k=k)),
        ("cr", CustomRegressor())
    ])
    search = GridSearchCV(pipeline,
    param_grid = {"cr__regressors": estimators},
    cv = 3,
    n_jobs = -1,
    scoring = "neg_mean_squared_error")
    search.fit(train_data, train_label)
    best_regressor = search.best_estimator_
    return best_regressor

def get_params():
    """
    This functions searches for the files that contain the optimal hyperparameters. If found,
    returns them as a tuple, otherwise it returns None.
    """
    try:
        ada_params = pd.read_csv("params.csv", index_col="ID")
        grad_params = pd.read_csv("grad_params.csv", index_col="ID")
        knr_params = pd.read_csv("knr_params.csv", index_col="ID")
    except FileNotFoundError:
        print("Parameter files not found, will use default hyperparameters for regressors.")
        print("It is recommended to run findparams.py file once to find optimal hyperparameters, if you have time.")
        return None
    else:
        return ada_params, grad_params, knr_params

def get_estimators(params, col):
    """
    Parameters:
    params: List of parameter dataframes. Expected length of 3.
    col: Column name of the current iteration.
    -----------------------------------------------------------
    This function takes the optimized hyperparameters at each
    iteration, then creates unfitted regressors. After that it
    puts each of them into a tuple (name, estimator) with name
    being a string and estimator being the instance of the 
    model object. After that, it returns all possible 
    combinations of these 3 tuples, so that our combined
    classifier can try every combination with cross-validation
    and get the best estimator.
    If params is None, return None.
    """
    if params:
        lr, loss, n = params[0][col] 
        abr = AdaBoostRegressor(n_estimators = int(n),
            loss = loss,
            learning_rate = float(lr))
        n, depth, loss, learning_rate, alpha = params[1][col]
        gbr = GradientBoostingRegressor(n_estimators = int(n),
            max_depth = int(depth),
            loss = loss,
            learning_rate = float(learning_rate),
            alpha = float(alpha))
        algorithm, n_neighbors, p, weights = params[2][col]
        knr = KNeighborsRegressor(n_jobs = -1,
            algorithm = algorithm,
            n_neighbors = int(n_neighbors),
            p = int(p),
            weights = weights)
        estimators = [("abr", abr), ("gbr", gbr), ("knr", knr)]
        est = []
        for i in range(len(estimators)):
            tmp = ([list(x) for x in combinations(estimators, i+1)])
            for x in tmp:
                est.append(x)
        return est
    else:
        return None

def train(x_tra, y_tra):
   
    """
    The method creates a learning model and trains it by using training data.
    Parameters
    ----------
    x_tra: features of training data
    y_tra: labels of training data
    x_tst: features of testing data
    """

    params = get_params()
    models = {}
    for col in y_tra:

        regressor = grid_search(x_tra, y_tra[col], params, col)

        models[col] = regressor

    return models

def predict(x_tst, model):

    """
    The method predicts labels for testing data samples by using trained learning model.
    Parameters
    ----------
    x_tst: features of testing data
    model: trained learning model
    """

    predictions = pd.DataFrame()
    for col in model:
        predictions[col] = model[col].predict(X_test)
    return predictions

def cross_validation(x_tra, y_tra):
    """
    Parameters:
    data: Training data to perform 5-Fold cross-validation on.
    label: Labels for training data.
    ----------------------------------------------------------
    This function performs 5-Fold cross validation on the training
    set. After splitting the data into 5 folds, iterates over each
    fold and gets training(120 samples) and testing(30 samples) sets,
    then trains our regressor model on the sample. After each iteration
    in each fold, it stores predictions in the predict_test dataframe.
    After predicting every label in each fold, it appends the predict_test
    dataframe to final_predict, then prints out the score by calling scorer
    function.
    """
    cv = KFold(n_splits = 5, shuffle=True, random_state=1)
    final_predict = pd.DataFrame()
    msqr = []
    mabs = []
    pearson = []
    for fold in cv.split(x_tra):
        X_train, X_test = x_tra.iloc[fold[0]], x_tra.iloc[fold[1]] 
        y_train, y_test = y_tra.iloc[fold[0]], y_tra.iloc[fold[1]]
        predict_test = pd.DataFrame()
        params = get_params()
        for col in y_train:
            regressor = grid_search(X_train, y_train[col], params, col)

            predict_test[col] = regressor.predict(X_test)

        msqr.append(mse(predict_test.to_numpy().flatten(), y_test.to_numpy().flatten()))
        mabs.append(mae(predict_test.to_numpy().flatten(), y_test.to_numpy().flatten()))
        pearson.append(pr(predict_test.to_numpy().flatten(), y_test.to_numpy().flatten()))
        final_predict = final_predict.append(predict_test)
    print("MSE:")
    for i, stat in enumerate(mabs):
        print(i+1, stat)
    print("PCC:")
    for i, stat in enumerate(pearson):
        print(i+1, stat)
    print(statistics.mean(msqr), statistics.stdev(msqr))
    print(statistics.mean(mabs), statistics.stdev(mabs))
    print(statistics.mean(i[0] for i in pearson), statistics.stdev(i[0] for i in pearson))

def write_output(filename, predictions):

    """
    Writes the outputted predictions to a file.
    Parameters
    ----------
    filename: file path for saving file
    predictions: pandas.dataframe object containing predictions
    """
    
    predictions = predictions.to_numpy().flatten()
    submission = pd.DataFrame(predictions, columns = ["Predicted"])
    submission.index.name = "ID"
    submission.to_csv(filename)

files = ["train_t0.csv", "train_t1.csv", "test_t0.csv"]

X_train, y_train, X_test = load_data(files)
X_train, X_test = preprocessing(X_train, y_train, X_test)

#Uncomment the following function call to perform cross validation.
#cross_validation(X_train, y_train)

models = train(X_train, y_train)
predictions = predict(X_test, models)
write_output("submission.csv", predictions)